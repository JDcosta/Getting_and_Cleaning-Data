README
================

#### Getting and Cleaning Data generated by the Human Activity Recognition (HAR) Using Smartphones Project (“Project” from herein out)

#### Project Background and Summary:

The Human Activity Recognition (HAR) using Smartphonesis premised on
predicting the movements of a human through the processing of
information retreived from body-worn sensors. The sensors generate
voluminous movement data (i.e raw data) which is pre-processed and made
available to the public as a dataset(s).

For the purposes of the Project, the raw data is linked to from the
course website at
<https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip>.
It represents raw ( with some pre-processing) values of quantitative and
qualitative movement-related variables collected from the accelerometers
and gyroscopes embedded in the Samsung Galaxy S smartphones worn by a
group of human subjects. The goal of the Project is to process the raw
data using a R script or scripts ‘run\_analysis.R’ and prepare a tidy
data set (tidy\_Data.txt) to be used for later analysis. A tidy data set
is one where there is one table for each “type”of variable with one
observation per row and one variable per column. The raw dataset and the
tidy data set are more particularly described in the markdown file
‘CodeBook.md’

#### Contents of this GitHub repository

This GitHub repository contains the following: - ‘README.md’ which is
this file. It provides details of the R scripts and the interconnections
betwen them and their operation to transform the raw data into the tidy
Data set. - ‘CodeBook.md’ that describes the variables, the raw data set
and its structure, and any transformations or work that was performed to
clean up the raw data and obtain the tidy Data. It includes all
variables and summaries calculated, along with units, and any other
relevant information. -‘run\_analysis.R’, the R script that was used to
create the tidy Data set as described in a following paragraph of this
README. - ‘tidy\_Data.txt’ The tidy\_dataset.txt file in this directory
is a tidy subset of the data provided in the Human Activity Recognition
Using Smartphones Data Set.

##### Raw Data (input)-\> Process Engine (‘run\_analysis.R’) -\>output tidy\_Data.txt

The R script ‘run\_analysis.R’ is the process engine through which the
following processes are implemented:

1.  As explained in the CodeBook.md, the raw dataset is partitioned into
    two datasets - the training and the test data sets.The script
    ‘run\_analysis.R’ merges the training and the test sets to create
    one data set.(‘compositedb’)

2.  Extracts only the measurements on the mean and standard deviation
    for each measurement.

3.  Uses descriptive activity names to name the activities in the
    compositedb data set

4.  Appropriately labels the data set with descriptive variable names.

5.  From the data set in step 4, creates a second, independent tidy data
    set with the average of each variable for each activity and each
    subject.

#### Installation of ‘run\_analysis.R’ and required libraries.

R script ‘run\_analysis.R’ downloads the raw dataset, cleans it and
outputs the tidy data set in the file tidy\_Data.txt

#### PHASE 1: Preparing to obtain data for the analysis

The dataset used for this project is UCI HAR Dataset Human Activity
Recognition (HAR) using Smartphones database details of which are
described at \#\#\#\#\#\#
<http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones>

The dataset is in a zip folder- “Dataset.zip” which is hosted at the
following URL \#\#\#\#\# URL \<-
“<https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip>”

go to RStudio and navigate to the working\_directory which will be the
project directory for this Project. you can do this by going RStudio -
Session and - Choose directory the project files will be in a
subdirectory ./pData of the working directory under the directory
structure envisaged here.

The project dataset - UCI HAR Dataset, will be installed in the
directory .\\pData (Windows relative path and use of backslash). The
zipped folder Dataset.zip will unzip to .\\pData. If you have not
created it, it will be created by the run\_analysis.R script. The
project dataset will be at ( .\\pData\\UCI HAR Dataset )

#### STEP01

navigate RStudio to the working directory of your choosing for this
project through the Session menu- Set Working Directory - Choose
Directory menu pick Verify the directory by running working directory
\<- getwd()

Place the run\_analysis.R script in the working directory and run it at
the RStudio command line

source(“run\_analysis.R”)

###### The script will begin by loading the following libraries

library(dplyr)  
library(knitr) library(reshape2) library(stringr)

Next the script will look for the sub-directory ‘pData’ (since this is
the particular directory structure chosen for this scripting. Other
directory structures and configurations can be coded by modifying the
script. the HAR dataset will end up in this sub-directory \< “pData” \>
of the working\_directory. If ./pData does not exist, it will be
programatically created.

In this script, ./pData represnts the project directory distinct from
and a subdirectory of the working directory referenced above.

###### Check if .\\pData exists. If not, create it.

if(\!file.exists(“.\\pData”)){  
dir.create(“.\\pData”)  
}

#### STEP02

the next few steps are designed to avoid unnecessary programmatic
overhead since datasets can be very large and duplicate download steps
are not recommended particulary if the run\_analysis.R script is
repeatedly rerun in the course of experimentation with the Data sets

\#check if pData folder already contains the unzipped folder \#UCI HAR
Dataset. If it does then PHASE 1 is complete. Go to STEP03
if(\!file.exists(“.\\pData\\UCI HAR Dataset”)){

\#In the event the pData directory folder does not contain the unzipped
folder \#UCI HAR Datase then

\#Check if it contains the downloaded zip file Dataset.zip if it does
not contain the zip folder, download zip folder Dataset.zip
if(\!file.exists(“.\\pData\\Dataset.zip”)){

    download.file(URL,destfile=".\\pData\\Dataset.zip",mode = "wb")

} At this point there is a Dataset.zip folder available in the project
directory unzip Dataset.zip to obtain the project dataset UCI HAR
Dataset in pData

} \#\#\#\#\#\# extract files from the zip folder. See CODEBOOK.rmd for
details of the files \#the structure of the extracted dataset is \#two
folders test and train and four files - features.txt,
features\_info.txt, \#activity labels.txt and README.txt \#the folder
train has files X\_train.txt, subject\_train.txt and y\_train.txt \#the
folder test has corresponding files to folder train

###### extract the data files into the project folder

unzip(zipfile=“./pData/Dataset.zip”,exdir=“./pData”)

#### STEP03

\#Check out and list the contents of UCI HAR Dataset datPath \<-
“.\\pData\\UCI HAR Dataset” datFiles \<- list.files(datPath,
recursive= TRUE) \#print(datFiles)

\#set up the R environment variables for appropriate representation of
numeric data \#R write.table is internally coded to default to the
representation of numeric data \#and the number of digits after the
decimal based on R’s scipen and digits environment variables

\#set the scipen and digits options that are effective for this dataset
\#For the R environment of this machine, the values of the scipen and
digits \#environmental variables can be checked by running
options(“scipen”) Options(“digits”) \#note both values. In this
instance, scipen is 0 and digiits is 7 \#override the default values

options(scipen= 27, digits=8)

#### STEP04 Read data from each of the files into respective data frames

\#simultaneously change some of the original column names to descriptive
activity names

#### read activity and feature labels

activitylabels \<- read.table(“./pData/UCI HAR
Dataset/activity\_labels.txt”,col.names = c(“activityidentifier”,
“activitytype”),colClasses = c(“integer”,
“character”),stringsAsFactors=FALSE ) features \<-
read.table(“./pData/UCI HAR Dataset/features.txt”, as.is=TRUE,
col.names =c (“featureidentifier”, “featurename”), colClasses =
c(“integer”, “character”),stringsAsFactors=FALSE)

#### read data for the “Test” partition of the dataset

subjecttest \<- read.table(“./pData/UCI HAR
Dataset/test/subject\_test.txt”, col.names =
c(“subjectidentifier”),colClasses =
c(“integer”),stringsAsFactors=FALSE) xtest \<-
read.table(“./pData/UCI HAR Dataset/test/X\_test.txt”,colClasses=
c(“numeric”),stringsAsFactors=FALSE) ytest \<- read.table(“./pData/UCI
HAR Dataset/test/y\_test.txt”, col.names = c(“activityidentifier”),
colClasses=c(“integer”),stringsAsFactors=FALSE)

\#set the preferred number of digits after the decimal point \#this is
based on the further uses of the tidy data set. Not all applications
\#need to process 11 digits after the decimal point (default for R)

xtest \<- xtest %\>% dplyr::mutate(across(where(is.numeric), \~ round(.,
digits = 8)))

#### read data for the “Train” partition of the dataset

subjecttrain \<- read.table(“./pData/UCI HAR
Dataset/train/subject\_train.txt”, col.names =
c(“subjectidentifier”),colClasses =
c(“integer”),stringsAsFactors=FALSE) xtrain \<-
read.table(“./pData/UCI HAR Dataset/train/X\_train.txt”,colClasses=
c(“numeric”),stringsAsFactors=FALSE) ytrain \<-
read.table(“./pData/UCI HAR Dataset/train/y\_train.txt”, col.names =
c(“activityidentifier”), colClasses=c(“integer”),stringsAsFactors=FALSE)
\#set the preferred number of digits after the decimal point - same as
the test partition xtrain \<- xtrain %\>%
dplyr::mutate(across(where(is.numeric), \~ round(., digits = 8)))

#### STEP05: combine the subjecttest, ytest and Xtest dataframes into a “test” dataframe

test \<- cbind(subjecttest, ytest, xtest)

\#combine the subjecttrain, ytrain, and xtrain dataframes into a “train”
dataframe train \<- cbind(subjecttrain, ytrain, xtrain)

\#combine test and train datasets into a single compositedb data set.
\#presumption that the “training” phase will precede the “testing” phase
in the \#experiment

compositedb \<- rbind (train, test)

#### STEP06 rename column names of compositedb to more descriptive activity types with the following steps

\#The dataframe has the column names of the original raw dataset. These
are not descriptive.

colnames(compositedb) \<- c(colnames(compositedb\[,1:2\]),
features$featurename)

\#reduce the dataset by keeping only those columns that are needed for
this project \#those are columns which contain “mean” and “Std” related
data. \#this next step only provides the logical vector corresponding to
columns to be retained

colindices \<- sapply(colnames(compositedb), FUN = function(x)
grepl(“mean\\(\\)|std\\(\\)”, x))

\#make suitable modifications to account for the fact that two
dataframes were \#appended to the test and train data-frames from which
the compositedb was obtained

\#need to retain the subjectidentifier and activityidentifier columns
colindices\[1:2\] = TRUE

\#obtain the numerical position of the columns that will be retained by
using the \#logical vector computed earlier, Only retain the columns
corresponding to those \#positions. Compositedb now has only the
required columns. compositedb \<- compositedb\[, which(colindices)\]

#### STEP07 clean the column names of the new smaller dataframe compositedb so that the variable names reflect descriptive names

colnames(compositedb) \<- colnames(compositedb) %\>% str\_replace(“^f”,
“Freq”) %\>% str\_replace(“^t”, “Time”) %\>% str\_replace(“Acc”,
“Accel”) %\>% str\_replace(“Mag”, “Magnitude”) %\>%
str\_replace(“Gyro”, “Gyroscope”) %\>% str\_replace(“BodyBody”,
“Body”) %\>% str\_replace(“\[(\]\[)\]-?”, "“) %\>%
str\_replace(”X\(", "_X") %>%  str_replace("Y\)“,”\_Y“) %\>%
str\_replace(”Z$“,”\_Z“) %\>% str\_replace(”mean“,”Mean“) %\>%
str\_replace(”std“,”STD“) %\>% str\_replace\_all(”-“,”.")

#### replace activityidentifier with activitytype in column 2 for tidy Data reporting purposes

\#The factor activityidentifier used thus far carries no particular
descriptive connotation \#except that it is linked to the activitytype
through the activitylabel dataframe. mutate(compositedb,
as.character(activityidentifier)) compositedb\[,
“activityidentifier”\]\<-
activitylabels$activitytype\[compositedb\[, “activityidentifier”\]\]
\#\#\#\# change the column name of column 2 to ‘activitytype’ from
‘activityidentifier’ names(compositedb)\[2\] \<- c(“activitytype”)

#### Step08 create factors for the Subjectidentifier and Activity variables

compositedb\[, “subjectidentifier”\] \<- factor(compositedb\[,
“subjectidentifier”\]) compositedb\[, “activitytype”\] \<-
factor(compositedb\[, “activitytype”\])

#### Step09 Create an independent second tidy data set ‘x’ with the average of \#\#\#\# each variable for each activity and each subject

\#x \<- compositedb %\>% group\_by(activitytype,subjectidentifier) %\>%
dplyr::summarize(across(.cols=everything(), .fns=mean))

\#\#\#\#output grouped by subjectidentifier in tidy\_Data.txt
\#\#\#\#output grouped by activitytype by switching the order of
variables in \#\#\#\#group\_by

x \<- compositedb %\>% group\_by(subjectidentifier, activitytype) %\>%
summarise\_each(list(mean = mean))

#### format the tidy data set data frame to get the desired output

format(x, justify= “left”, trim=FALSE, digit=8, nsmall=4)

#### output the tidy dataset as file tidy\_Data.txt

write.table(x,file=“tidy\_Data.txt”, quote= FALSE, row.names=FALSE,
col.names=TRUE, append=FALSE, sep=" ")

#### restore scipen and digits to their default values

options(scipen =0, digits=7) \#default for R

#### successful run

The output of the run\_analysis.R script will be a tidy\_Data.txt file
with the tidy data. It will be in the working directory
